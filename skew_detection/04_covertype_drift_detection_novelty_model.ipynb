{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_covertype_drift_detection_novelty_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebLFeOqfFkTu",
        "colab_type": "text"
      },
      "source": [
        "# Computing Drift Score using Novelty Detection Modeling\n",
        "\n",
        "This tutorial shows how to use a novelty detection model to detect skews between data split (e.g. training and serving). Novelty detection models can identify whether an instance blongs to a population, or is considered as an outlier. \n",
        "\n",
        "The tutorial covers the following steps:\n",
        "\n",
        " 1. Download training and serving  data splits\n",
        " 2. Train an Elliptic Envelope model using the training data\n",
        " 3. Test the model on normal and mutated datasets\n",
        " 4. Implement an Apache Beam pipeline to compute drift score in request-response BigQuery data\n",
        " 5. Run the pipeline and display drift detection output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT-Pj-s1asEh",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YAsA6ZIKeHq",
        "colab_type": "text"
      },
      "source": [
        "### Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac7sDkawFX55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q apache-beam[interactive]\n",
        "!pip install -U -q pandas\n",
        "!pip install -U -q sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3qp8K3BKp4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Automatically restart kernel after installs\n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOy7TgT5K8-Y",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXWABKNUFkDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tensorflow import io as tf_io\n",
        "import apache_beam as beam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import json\n",
        "from collections import namedtuple\n",
        "\n",
        "print(\"Apache Beam version: {}\".format(beam.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca91jSulyu_R",
        "colab_type": "text"
      },
      "source": [
        "### Configure GCP environment settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZlb6ZIzyvOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJECT_ID = \"sa-data-validation\"\n",
        "BUCKET = \"sa-data-validation\"\n",
        "BQ_DATASET_NAME = 'prediction_logs'\n",
        "BQ_TABLE_NAME = 'covertype_classifier_logs'  \n",
        "MODEL_NAME = 'covertype_classifier'\n",
        "MODEL_VERSION = 'v1'\n",
        "!gcloud config set project $PROJECT_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beikXYYEy56r",
        "colab_type": "text"
      },
      "source": [
        "### Authenticate your GCP account\n",
        "This is required if you run the notebook in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPmptHu2y6A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  print(\"Colab user is authenticated.\")\n",
        "except: pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK0oWyt7LD_3",
        "colab_type": "text"
      },
      "source": [
        "### Create a local workspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWL4Ifwubtn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GCS_DATA_LOCATION = 'gs://workshop-datasets/covertype/data_validation'\n",
        "WORKSPACE = './workspace'\n",
        "DATA_DIR = os.path.join(WORKSPACE, 'data')\n",
        "TRAIN_DATA = os.path.join(DATA_DIR, 'train.csv') \n",
        "EVAL_DATA = os.path.join(DATA_DIR, 'eval.csv') \n",
        "MODELS_DIR = os.path.join(WORKSPACE, 'models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXe720dJd0-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tf_io.gfile.exists(WORKSPACE):\n",
        "  print(\"Removing previous workspace artifacts...\")\n",
        "  tf_io.gfile.rmtree(WORKSPACE)\n",
        "\n",
        "print(\"Creating a new workspace...\")\n",
        "tf_io.gfile.makedirs(WORKSPACE)\n",
        "tf_io.gfile.makedirs(DATA_DIR)\n",
        "tf_io.gfile.makedirs(MODELS_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KPT7KfudAUf",
        "colab_type": "text"
      },
      "source": [
        "## 1. Download Data Splits\n",
        "\n",
        "We use the [covertype](https://archive.ics.uci.edu/ml/datasets/covertype) from UCI Machine Learning Repository. The task is to Predict forest cover type from cartographic variables only. \n",
        "\n",
        "The dataset is preprocessed, split, and uploaded to the `gs://workshop-datasets/covertype` public GCS location. \n",
        "\n",
        "We use this version of the preprocessed dataset in this notebook. For more information, see [Cover Type Dataset](https://github.com/GoogleCloudPlatform/mlops-on-gcp/tree/master/datasets/covertype)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aCzZNfXcqVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp gs://workshop-datasets/covertype/data_validation/training/dataset.csv {TRAIN_DATA}\n",
        "!gsutil cp gs://workshop-datasets/covertype/data_validation/evaluation/dataset.csv {EVAL_DATA}\n",
        "!wc -l {TRAIN_DATA}\n",
        "!wc -l {EVAL_DATA}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zCYn7e6dRWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.read_csv(TRAIN_DATA).head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55ogDNC4ZVs5",
        "colab_type": "text"
      },
      "source": [
        "## 2. Train an Elliptic Envelope Model using Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8LV9fC_ZzBp",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. Define metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OAiQg_fZyNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TARGET_FEATURE_NAME = 'Cover_Type'\n",
        "\n",
        "CATEGORICAL_FEATURE_NAMES = [\n",
        "    'Soil_Type',\n",
        "    'Wilderness_Area'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj4K29vUofme",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp0ghh6C188w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv(TRAIN_DATA).drop(TARGET_FEATURE_NAME, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUjyeroWbhdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoders = dict()\n",
        "\n",
        "for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
        "  encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "  encoder.fit(train_data[[feature_name]])\n",
        "  encoders[feature_name] = encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpIfUb8vczNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(data_frame):\n",
        "\n",
        "  if type(data_frame) != pd.DataFrame:\n",
        "    data_frame = pd.DataFrame(data_frame)\n",
        "  \n",
        "  data_frame = data_frame.reset_index()\n",
        "  for feature_name, encoder in encoders.items():\n",
        "    encoded_feature = pd.DataFrame(\n",
        "      encoder.transform(data_frame[[feature_name]]).toarray()\n",
        "    )\n",
        "    data_frame = data_frame.drop(feature_name, axis=1)\n",
        "    encoded_feature.columns = [feature_name+\"_\"+str(column) \n",
        "                               for column in encoded_feature.columns]\n",
        "    data_frame = data_frame.join(encoded_feature)\n",
        "  \n",
        "  return data_frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCMDdQ2coknt",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqcYr03tqEF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prepared_training_data = prepare_data(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaGeGFL2mVlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "\n",
        "model = EllipticEnvelope(contamination=0.)\n",
        "\n",
        "print(\"Fitting...\")\n",
        "t0 = time.time()\n",
        "model.fit(prepared_training_data)\n",
        "t1 = time.time()\n",
        "print(\"Model is fitted in {} seconds.\".format(round(t1-t0)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PAREHDGaCsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statistics\n",
        "\n",
        "training_distances = model.mahalanobis(prepared_training_data)\n",
        "model._mean = statistics.mean(training_distances)\n",
        "model._stdv = statistics.stdev(training_distances)\n",
        "print(\"training distance mean: {}\".format(round(model._mean, 5))) \n",
        "print(\"training distance stdv: {}\".format(round(model._stdv, 5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYhjKTmExHAP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Test the Elliptic Envelope Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N6mmbYETH7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_drift_score(model, data_frame, stdv_units=2):\n",
        "  \n",
        "  distances = model.mahalanobis(data_frame)\n",
        "  threshold = model._mean + (stdv_units * model._stdv)\n",
        "  score = len([v for v in distances if v >= threshold]) / len(data_frame.index)\n",
        "  \n",
        "  return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9_91krqigO",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Generate mutated serving data\n",
        "We are going to generate a dataset with mutated data points, by shuffling each column values accross the rows, creating rows with random combination of feature values.\n",
        "\n",
        "This method makes sure that the values of each feature, independently, follows the distribution of the original serving data. However, the joint distribution is completely different, since we generate feature values independetly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEu4Eg1cpjOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "serving_data = pd.read_csv(EVAL_DATA).drop('Cover_Type', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sox72_k1t9o5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_values(dataframe):     \n",
        "  shuffeld_dataframe = dataframe.copy()\n",
        "  for column_name in dataframe.columns:\n",
        "    shuffeld_dataframe[column_name] = shuffeld_dataframe[column_name].sample(\n",
        "        frac=1.0).reset_index(drop=True)\n",
        "\n",
        "  return shuffeld_dataframe\n",
        "\n",
        "mutated_serving_data = shuffle_values(serving_data)\n",
        "mutated_serving_data.head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLcclzLKfOpx",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Use the model to score data for drift\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glmHgv5Gfb4c",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Compute the drift score on normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dRRzH6KgDKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stdv_units = 2\n",
        "prepared_serving_data = prepare_data(serving_data)\n",
        "score = compute_drift_score(model, prepared_serving_data, stdv_units)\n",
        "percentage = round(score *100, 2)\n",
        "print(\"There is {}% of the data points more than {} standard deviation units away from the mean of the training data\".format(percentage, stdv_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gugytaZhfcS7",
        "colab_type": "text"
      },
      "source": [
        "### 3.3. Compute the drift score on normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_xWczW9pzHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prepared_mutated_data = prepare_data(mutated_serving_data)\n",
        "score = compute_drift_score(model, prepared_mutated_data, stdv_units)\n",
        "percentage = round(score *100, 2)\n",
        "print(\"There is {}% of the data points more than {} standard deviation units away from the mean of the training data\".format(percentage, stdv_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BJmtt6ezA9u",
        "colab_type": "text"
      },
      "source": [
        "## 4: Implement an Apache Beam pipeline to compute drift score in request-response BigQuery data\n",
        "\n",
        "This pipeline performs the following steps:\n",
        "1. Reads and parses the data from request-response logs table in BigQuery\n",
        "2. Use the Elliptic Envelope novelty detection model to identify outliers\n",
        "3. Compute the percentage of the data points detected as outliers as the drift score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNt6gQiaziPg",
        "colab_type": "text"
      },
      "source": [
        "### 4.1. Prepare helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDILrGNg5XDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def parse_batch_data(log_records):\n",
        "  data_dict = defaultdict(list)\n",
        "\n",
        "  for log_record in log_records:\n",
        "    raw_data = json.loads(log_record['raw_data'])\n",
        "    for raw_instance in raw_data['instances']:\n",
        "      for name, value in raw_instance.items():\n",
        "        data_dict[name].append(value[0])\n",
        "\n",
        "  return data_dict\n",
        "\n",
        "\n",
        "def score_data(data, model, stdv_units=2):\n",
        "  distances = model.mahalanobis(data)\n",
        "  threshold = model._mean + (stdv_units * model._stdv)\n",
        "  outlier_count = len([v for v in distances if v >= threshold])\n",
        "  records_count = len(data)\n",
        "  return {'outlier_count': outlier_count, 'records_count': records_count}\n",
        "\n",
        "\n",
        "def aggregate_scores(items):\n",
        "  outlier_count = 0 \n",
        "  records_count = 0\n",
        "  for item in items:\n",
        "    outlier_count += item['outlier_count']\n",
        "    records_count += item['records_count']\n",
        "  return {'outlier_count': outlier_count, 'records_count': records_count}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xakztiZY7SlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_query(bq_table_fullname, model_name, model_version, start_time, end_time):\n",
        "  query = \"\"\"\n",
        "  SELECT raw_data\n",
        "  FROM {}\n",
        "  WHERE model = '{}'\n",
        "  AND model_version = '{}'\n",
        "  \"\"\".format(bq_table_fullname, model_name, model_version, start_time, end_time)\n",
        "\n",
        "  return query"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BRke4Z62c4S",
        "colab_type": "text"
      },
      "source": [
        "### 4.2. Implement Beam pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ClnVBlnzEkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_pipeline(args):\n",
        "\n",
        "  options = beam.options.pipeline_options.PipelineOptions(**args)\n",
        "  args = namedtuple(\"options\", args.keys())(*args.values())\n",
        "  query = get_query(\n",
        "      args.bq_table_fullname, args.model_name, \n",
        "      args.model_version, \n",
        "      args.start_time, \n",
        "      args.end_time\n",
        "  )\n",
        "\n",
        "  print(\"Starting the Beam pipeline...\")\n",
        "  with beam.Pipeline(options=options) as pipeline:\n",
        "    (\n",
        "        pipeline \n",
        "        | 'ReadBigQueryData' >> beam.io.Read(\n",
        "            beam.io.BigQuerySource(query=query, use_standard_sql=True))\n",
        "        | 'BatchRecords' >> beam.BatchElements(\n",
        "            min_batch_size=100, max_batch_size=1000)\n",
        "        | 'InstancesToBeamExamples' >> beam.Map(parse_batch_data)\n",
        "        | 'PrepareData' >> beam.Map(prepare_data)\n",
        "        | 'ScoreData' >> beam.Map(\n",
        "            lambda data: score_data(data, args.drift_model, stdv_units=1))\n",
        "        | 'CombineResults' >> beam.CombineGlobally(aggregate_scores)\n",
        "        | 'ComputeRatio' >> beam.Map(\n",
        "            lambda result: {\n",
        "                \"outlier_count\": result['outlier_count'], \n",
        "                \"records_count\": result['records_count'],\n",
        "                \"drift_ratio\": result['outlier_count'] / result['records_count']\n",
        "                })\n",
        "         | 'WriteOutput' >> beam.io.WriteToText(\n",
        "             file_path_prefix=args.output_file_path, num_shards=1, shard_name_template='')\n",
        "    )\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByWZEfpr2xO4",
        "colab_type": "text"
      },
      "source": [
        "## 5. Run Pipeline and Display Drift Detection Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbntsBEo2cKW",
        "colab_type": "text"
      },
      "source": [
        "### 5.1. Configure pipeline parameter settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_qNMilj2xUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "job_name = 'drift-detection-{}'.format(\n",
        "    datetime.utcnow().strftime('%y%m%d-%H%M%S'))\n",
        "bq_table_fullname = \"{}.{}.{}\".format(\n",
        "    PROJECT_ID, BQ_DATASET_NAME, BQ_TABLE_NAME)\n",
        "runner = 'InteractiveRunner'\n",
        "output_dir = os.path.join(WORKSPACE, 'output')\n",
        "output_path = os.path.join(output_dir, 'drift_output.json')\n",
        "start_time = '2020-07-05 00:00:00 UTC'\n",
        "end_time = '2020-07-06 23:59:59 UTC'\n",
        "\n",
        "args = {\n",
        "    'job_name': job_name,\n",
        "    'runner': runner,\n",
        "    'bq_table_fullname': bq_table_fullname,\n",
        "    'model_name': MODEL_NAME,\n",
        "    'model_version': MODEL_VERSION,\n",
        "    'start_time': start_time,\n",
        "    'end_time': end_time,\n",
        "    'output_file_path': output_path,\n",
        "    'project': PROJECT_ID,\n",
        "    'reference_schema': reference_schema,\n",
        "    'drift_model': model\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnwTL944zcne",
        "colab_type": "text"
      },
      "source": [
        "### 5.2. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJstUEVC2yw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r {output_dir}\n",
        "\n",
        "print(\"Running pipeline...\")\n",
        "%time run_pipeline(args)\n",
        "print(\"Pipeline is done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmjApTrazwqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls {output_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwmUdMuOzg4d",
        "colab_type": "text"
      },
      "source": [
        "### 5.3. Display the drift detection output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cKtvu4PIOfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dirft_results = json.loads(open(output_path).read()).items()\n",
        "for key, value in dirft_results:\n",
        "  if key == 'drift_ratio':\n",
        "    value = str(round(value * 100, 2)) +'%'\n",
        "  print(key,':', value)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}