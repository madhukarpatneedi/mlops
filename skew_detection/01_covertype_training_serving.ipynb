{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-covertype-training-serving.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YSXq_Y36c_g",
        "colab_type": "text"
      },
      "source": [
        "# Serving a Keras Model on AI Platform Prediction with request-response logging to BigQuery\n",
        "\n",
        "This tutorial shows how to train a TensorFlow classification model, using the Keras API, and deploy it to AI Platform for online prediction. The tutorial also shows how to enable [AI Platform Prediction request-response logging](https://cloud.google.com/ai-platform/prediction/docs/online-predict#requesting_logs_for_online_prediction_requests) to BigQuery.\n",
        "\n",
        "The tutorial covers the following steps:\n",
        "\n",
        "1. Prepare the data and generate metadata \n",
        "2. Train and evaluate a TensorFlow classification model using Keras API\n",
        "3. Export the trained model as a SavedModel for serving\n",
        "4. Deploy the trained model to AI Platform Prediction \n",
        "5. Enabled request-response logging to BigQuery\n",
        "6. Query logs from BigQuery\n",
        "\n",
        "\n",
        "This example uses **TensorFlow 2.x**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2iZLfjnNxK9",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7VJ2GIVM5SJ",
        "colab_type": "text"
      },
      "source": [
        "### Install packages and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm5FTgF69bll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q -U tensorflow==2.1\n",
        "!pip install -U -q google-api-python-client\n",
        "!pip install -U -q pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AXP7PUBNGt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Automatically restart kernel after installs\n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdqP-e0xNh13",
        "colab_type": "text"
      },
      "source": [
        "### Configure Google Cloud environment settings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GufMPSFuOSiZ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "PROJECT_ID = '[your-google-project-id]'\n",
        "BUCKET = '[your-bucket-name]'\n",
        "REGION = '[your-region-id]'\n",
        "!gcloud config set project $PROJECT_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_9K14ssNRnC",
        "colab_type": "text"
      },
      "source": [
        "### Authenticate your Google Cloud account\n",
        "\n",
        "This is required if you run the notebook in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWzmq-55CZfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  print(\"Colab user is authenticated.\")\n",
        "except: pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewFHEkCaO_mW",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4pR1SEo6Tra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "\n",
        "print(\"TF version: {}\".format(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGkiBa7eQYKm",
        "colab_type": "text"
      },
      "source": [
        "### Define constants\n",
        "\n",
        "You can change the default values for the following constants\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIVPK2qaQYRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOCAL_WORKSPACE = './workspace'\n",
        "LOCAL_DATA_DIR = os.path.join(LOCAL_WORKSPACE, 'data')\n",
        "BQ_DATASET_NAME = 'prediction_logs'\n",
        "BQ_TABLE_NAME = 'covertype_classifier_logs' \n",
        "MODEL_NAME = 'covertype_classifier'\n",
        "VERSION_NAME = 'v1' \n",
        "TRAINING_DIR = os.path.join(LOCAL_WORKSPACE, 'training')\n",
        "MODEL_DIR = os.path.join(TRAINING_DIR, 'exported_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmYHPLFgEA92",
        "colab_type": "text"
      },
      "source": [
        "### Create a local workspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XXOcV8BD_w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tf.io.gfile.exists(LOCAL_WORKSPACE):\n",
        "  print(\"Removing previous workspace artifacts...\")\n",
        "  tf.io.gfile.rmtree(LOCAL_WORKSPACE)\n",
        "\n",
        "print(\"Creating a new workspace...\")\n",
        "tf.io.gfile.makedirs(LOCAL_WORKSPACE)\n",
        "tf.io.gfile.makedirs(LOCAL_DATA_DIR)\n",
        "print(\"Workspace created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLUHs-gh_FnY",
        "colab_type": "text"
      },
      "source": [
        "## 1. Dataset preparation and metadata definition\n",
        "\n",
        "The notebook uses the [covertype](https://archive.ics.uci.edu/ml/datasets/covertype) dataset from the UCI Machine Learning Repository. The task is to predict forest cover type from cartographic variables only.\n",
        "\n",
        "Note that the aim is to build and deploy a **minimal model** to showcase the AI Platform Prediction request-response **logging capabilities**.\n",
        "Such logs enable further analysis for detecting on the serving data skews.\n",
        "\n",
        "The dataset is preprocessed, split, and uploaded to the `gs://workshop-datasets/covertype` public Cloud Storage bucket. \n",
        "\n",
        "The notebook uses this version of the preprocessed dataset. For more information, see [Cover Type Dataset](https://github.com/GoogleCloudPlatform/mlops-on-gcp/tree/master/datasets/covertype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDH43VPLCCsS",
        "colab_type": "text"
      },
      "source": [
        "### 1.1. Download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK3t6GswFJaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOCAL_TRAIN_DATA = os.path.join(LOCAL_DATA_DIR, 'train.csv') \n",
        "LOCAL_EVAL_DATA = os.path.join(LOCAL_DATA_DIR, 'eval.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIjykELMB-Zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp gs://workshop-datasets/covertype/data_validation/training/dataset.csv {LOCAL_TRAIN_DATA}\n",
        "!gsutil cp gs://workshop-datasets/covertype/data_validation/evaluation/dataset.csv {LOCAL_EVAL_DATA}\n",
        "!wc -l {LOCAL_TRAIN_DATA}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkkFi52UUEfS",
        "colab_type": "text"
      },
      "source": [
        "View a sample of the downloaded data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV0j0nAezO_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.read_csv(LOCAL_TRAIN_DATA).head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUjRurNblnaw",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Define the metadata\n",
        "The following is the metadata of the dataset, which is used to create the data input function, the feature columns, and the serving function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72rDTLhcUxj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEADER = ['Elevation', 'Aspect', 'Slope','Horizontal_Distance_To_Hydrology',\n",
        "          'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
        "          'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
        "          'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Soil_Type',\n",
        "          'Cover_Type']\n",
        "\n",
        "TARGET_FEATURE_NAME = 'Cover_Type'\n",
        "\n",
        "TARGET_FEATURE_LABELS = ['0', '1', '2', '3', '4', '5', '6']\n",
        "\n",
        "NUMERIC_FEATURE_NAMES = ['Aspect', 'Elevation', 'Hillshade_3pm', \n",
        "                         'Hillshade_9am', 'Hillshade_Noon', \n",
        "                         'Horizontal_Distance_To_Fire_Points',\n",
        "                         'Horizontal_Distance_To_Hydrology',\n",
        "                         'Horizontal_Distance_To_Roadways','Slope',\n",
        "                         'Vertical_Distance_To_Hydrology']\n",
        "\n",
        "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
        "    'Soil_Type': ['2702', '2703', '2704', '2705', '2706', '2717', '3501', '3502', \n",
        "                  '4201', '4703', '4704', '4744', '4758', '5101', '6101', '6102', \n",
        "                  '6731', '7101', '7102', '7103', '7201', '7202', '7700', '7701', \n",
        "                  '7702', '7709', '7710', '7745', '7746', '7755', '7756', '7757', \n",
        "                  '7790', '8703', '8707', '8708', '8771', '8772', '8776'], \n",
        "    'Wilderness_Area': ['Cache', 'Commanche', 'Neota', 'Rawah']\n",
        "}\n",
        "\n",
        "FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys()) + NUMERIC_FEATURE_NAMES\n",
        "\n",
        "HEADER_DEFAULTS = [[0] if feature_name in NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME] else ['NA'] \n",
        "                   for feature_name in HEADER]\n",
        "\n",
        "NUM_CLASSES = len(TARGET_FEATURE_LABELS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20wwieKoJvL1",
        "colab_type": "text"
      },
      "source": [
        "## 2. Model training and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e3lk9FsJ_yO",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. Implement the data input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTX-t2HjJ_BP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RANDOM_SEED = 19830610\n",
        "import multiprocessing\n",
        "\n",
        "def create_dataset(file_pattern, \n",
        "                  batch_size=128, num_epochs=1, shuffle=False):\n",
        "  \n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        file_pattern=file_pattern,\n",
        "        batch_size=batch_size,\n",
        "        column_names=HEADER,\n",
        "        column_defaults=HEADER_DEFAULTS,\n",
        "        label_name=TARGET_FEATURE_NAME,\n",
        "        field_delim=',',\n",
        "        header=True,\n",
        "        num_epochs=num_epochs,\n",
        "        shuffle=shuffle,\n",
        "        shuffle_buffer_size=(5 * batch_size),\n",
        "        shuffle_seed=RANDOM_SEED,\n",
        "        num_parallel_reads=multiprocessing.cpu_count(),\n",
        "        sloppy=True,\n",
        "    )\n",
        "    return dataset.cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3ubvOGrUV5S",
        "colab_type": "text"
      },
      "source": [
        "The following code performs a test by reading some batches of data using the data input function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGcaJmcG3paA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 1\n",
        "for batch in create_dataset(LOCAL_TRAIN_DATA, batch_size=5, shuffle=False).take(2):\n",
        "  print(\"Batch: {}\".format(index))\n",
        "  print(\"========================\")\n",
        "  record, target = batch\n",
        "  print(\"Input features:\")\n",
        "  for key in record:\n",
        "    print(\" - {}:{}\".format(key, record[key].numpy()))\n",
        "  print(\"Target: {}\".format(target))\n",
        "  index += 1\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s8a7bMGKLWu",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. Create feature columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8pZSfQPHMrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def create_feature_columns():\n",
        "  feature_columns = []\n",
        "  \n",
        "  for feature_name in FEATURE_NAMES:\n",
        "    # Categorical features\n",
        "    if feature_name in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n",
        "      \n",
        "      vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
        "      vocab_size = len(vocabulary)\n",
        "      \n",
        "      # Create embedding column for categorical feature column with vocabulary\n",
        "      embedding_feature_column = tf.feature_column.embedding_column(\n",
        "          categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "              key=feature_name,\n",
        "              vocabulary_list=vocabulary), dimension=int(math.sqrt(vocab_size) + 1))\n",
        "            \n",
        "      feature_columns.append(embedding_feature_column)\n",
        "\n",
        "    # Numeric features\n",
        "    else:\n",
        "      numeric_column = tf.feature_column.numeric_column(feature_name)\n",
        "      feature_columns.append(numeric_column)\n",
        "\n",
        "  return feature_columns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLvEmxgvUgKd",
        "colab_type": "text"
      },
      "source": [
        "The following code tests the feature columns to be created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8XDvPsq8-mX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_columns = create_feature_columns()\n",
        "\n",
        "for column in feature_columns:\n",
        "  print(column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0pAN0jkKNmm",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. Create and compile the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E98fiPtQKTp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(params):\n",
        "\n",
        "  feature_columns = create_feature_columns()\n",
        "  \n",
        "  layers = []\n",
        "  layers.append(tf.keras.layers.DenseFeatures(feature_columns))\n",
        "  for units in params.hidden_units:\n",
        "    layers.append(tf.keras.layers.Dense(units=units, activation='relu'))\n",
        "    layers.append(tf.keras.layers.BatchNormalization())\n",
        "    layers.append(tf.keras.layers.Dropout(rate=params.dropout))\n",
        "  \n",
        "  layers.append(tf.keras.layers.Dense(units=NUM_CLASSES, activation='softmax'))\n",
        "  \n",
        "  model = tf.keras.Sequential(layers=layers, name='classifier')\n",
        "    \n",
        "  adam_optimzer = tf.keras.optimizers.Adam(learning_rate=params.learning_rate)\n",
        "\n",
        "  model.compile(\n",
        "        optimizer=adam_optimzer, \n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()], \n",
        "        loss_weights=None,\n",
        "        sample_weight_mode=None, \n",
        "        weighted_metrics=None, \n",
        "    )\n",
        "\n",
        "  return model  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjzFWQnSJFse",
        "colab_type": "text"
      },
      "source": [
        "### 2.4. Train and evaluate the experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9_yXPvF2Hkd",
        "colab_type": "text"
      },
      "source": [
        "#### Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9iW5NumKWWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_experiment(model, params):\n",
        "\n",
        "  # TensorBoard callback\n",
        "  LOG_DIR = os.path.join(TRAINING_DIR, 'logs')\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR)\n",
        "\n",
        "  # Early stopping callback\n",
        "  earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "      monitor='val_sparse_categorical_accuracy', \n",
        "      patience=3, \n",
        "      restore_best_weights=True\n",
        "  )\n",
        "\n",
        "  callbacks = [\n",
        "        tensorboard_callback,\n",
        "        earlystopping_callback]\n",
        "\n",
        "  # Train dataset\n",
        "  train_dataset = create_dataset(\n",
        "      LOCAL_TRAIN_DATA,\n",
        "      batch_size=params.batch_size,\n",
        "      shuffle=True)\n",
        "    \n",
        "  # Eval dataset\n",
        "  eval_dataset = create_dataset(\n",
        "      LOCAL_EVAL_DATA,\n",
        "      batch_size=params.batch_size)\n",
        "    \n",
        "  # Prep training directory\n",
        "  if tf.io.gfile.exists(TRAINING_DIR):\n",
        "    print(\"Removing previous training artifacts...\")\n",
        "    tf.io.gfile.rmtree(TRAINING_DIR)\n",
        "\n",
        "  print(\"Creating training directory...\")\n",
        "  tf.io.gfile.mkdir(TRAINING_DIR)\n",
        "\n",
        "  print(\"Experiment started...\")\n",
        "  print(\".......................................\")\n",
        "  \n",
        "  # Run train and evaluate\n",
        "  history = model.fit(\n",
        "    x=train_dataset, \n",
        "    epochs=params.epochs, \n",
        "    callbacks=callbacks,\n",
        "    validation_data=eval_dataset,\n",
        "  )\n",
        "\n",
        "  print(\".......................................\")\n",
        "  print(\"Experiment finished.\")\n",
        "  print(\"\")\n",
        "\n",
        "  return history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhYvbrrqJKmn",
        "colab_type": "text"
      },
      "source": [
        "#### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBCwS_usHvqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Parameters():\n",
        "    pass\n",
        "\n",
        "TRAIN_DATA_SIZE = 431010\n",
        "\n",
        "params = Parameters()\n",
        "params.learning_rate = 0.01\n",
        "params.hidden_units = [128, 128]\n",
        "params.dropout = 0.15\n",
        "params.batch_size =  265\n",
        "params.steps_per_epoch = int(math.ceil(TRAIN_DATA_SIZE / params.batch_size))\n",
        "params.epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf7FGOscJZ2P",
        "colab_type": "text"
      },
      "source": [
        "#### Run the experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew99zH72JRjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model(params)\n",
        "example_batch, _ = list(\n",
        "    create_dataset(LOCAL_TRAIN_DATA, batch_size=2, shuffle=True).take(1))[0]\n",
        "model(example_batch)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0DjaL7eI8Ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "history = run_experiment(model, params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhJ5qV0aJd0J",
        "colab_type": "text"
      },
      "source": [
        "#### Visualize training history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie7fi-q_JAhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "fig.set_size_inches(w=(10, 5))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "ax1.plot(history.history['sparse_categorical_accuracy'])\n",
        "ax1.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "ax1.set_title('Model Accuracy')\n",
        "ax1.set(xlabel='Iteration', ylabel='accuracy')\n",
        "ax1.legend(['Train', 'Eval'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "ax2.plot(history.history['loss'])\n",
        "ax2.plot(history.history['val_loss'])\n",
        "ax2.set_title('Model Loss')\n",
        "ax2.set(xlabel='Iteration', ylabel='loss')\n",
        "ax2.legend(['Train', 'Eval'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7q4uSu1KbXv",
        "colab_type": "text"
      },
      "source": [
        "## 3. Model export for serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulI3HOMLS-Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_KEY = 'predicted_label'\n",
        "SCORE_KEY = 'confidence'\n",
        "PROBABILITIES_KEY = 'probabilities'\n",
        "SIGNATURE_NAME = 'serving_default'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwDylJzoUTb1",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Implement serving input receiver functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iijp9_mV0gNn",
        "colab_type": "text"
      },
      "source": [
        "#### Serving function\n",
        "\n",
        "The notebook creates a serving input function that expects a features dictionary and returns:\n",
        "- Predicted class label\n",
        "- Prediction confidence\n",
        "- Prediction probabilities of all the classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQDJP47xnt9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_features_serving_fn(model):\n",
        "\n",
        "  @tf.function\n",
        "  def serve_features_fn(features):\n",
        "    probabilities = model(features)\n",
        "    labels = tf.constant(TARGET_FEATURE_LABELS, dtype=tf.string)\n",
        "    predicted_class_indices = tf.argmax(probabilities, axis=1)\n",
        "    predicted_class_label = tf.gather(\n",
        "        params=labels, indices=predicted_class_indices)\n",
        "    prediction_confidence = tf.reduce_max(probabilities, axis=1)\n",
        "    \n",
        "    return {\n",
        "        LABEL_KEY: predicted_class_label,\n",
        "        SCORE_KEY:prediction_confidence,\n",
        "        PROBABILITIES_KEY: probabilities}\n",
        "\n",
        "  return serve_features_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhYjXNxgjob1",
        "colab_type": "text"
      },
      "source": [
        "#### Feature spec\n",
        "\n",
        "The code creates the `feature_spec` dictionary for the input features with respect to the dataset metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D577fVOKbcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_spec = {}\n",
        "for feature_name in FEATURE_NAMES:\n",
        "    if feature_name in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n",
        "        feature_spec[feature_name] = tf.io.FixedLenFeature(\n",
        "            shape=[None], dtype=tf.string)\n",
        "    else:\n",
        "        feature_spec[feature_name] = tf.io.FixedLenFeature(\n",
        "            shape=[None], dtype=tf.float32)\n",
        "\n",
        "for key, value in feature_spec.items():\n",
        "  print(\"{}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sPh4f_tUX5n",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Export the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlQfiluTTuW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_input_signature = {\n",
        "    feature: tf.TensorSpec(shape=spec.shape, dtype=spec.dtype, name=feature)\n",
        "    for feature, spec in feature_spec.items()}\n",
        "\n",
        "signatures = {        \n",
        "    SIGNATURE_NAME: make_features_serving_fn(model).get_concrete_function(\n",
        "        features_input_signature)}\n",
        "\n",
        "model.save(MODEL_DIR, save_format='tf', signatures=signatures)\n",
        "print(\"Model is exported to: {}.\".format(MODEL_DIR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zmuFWnRU7eJ",
        "colab_type": "text"
      },
      "source": [
        "Verify the signature (inputs and outputs) of the exported model using `saved_model_cli`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyK7Yy0CCr1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!saved_model_cli show --dir {MODEL_DIR} --tag_set serve --signature_def {SIGNATURE_NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AQdyoPZUaKH",
        "colab_type": "text"
      },
      "source": [
        "### 3.3. Test exported model locally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG9MM4mkVK5A",
        "colab_type": "text"
      },
      "source": [
        "Create a sample instance for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gfRf20JVgn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "instances = [\n",
        "      { \n",
        "        'Soil_Type': ['7202'],\n",
        "        'Wilderness_Area': ['Commanche'],\n",
        "        'Aspect': [61],\n",
        "        'Elevation': [3091],\n",
        "        'Hillshade_3pm': [129],\n",
        "        'Hillshade_9am': [227],\n",
        "        'Hillshade_Noon': [223],\n",
        "        'Horizontal_Distance_To_Fire_Points': [2868],\n",
        "        'Horizontal_Distance_To_Hydrology': [134],\n",
        "        'Horizontal_Distance_To_Roadways': [0], \n",
        "        'Slope': [8], \n",
        "        'Vertical_Distance_To_Hydrology': [10],\n",
        "    }\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV07vVr1uBvr",
        "colab_type": "text"
      },
      "source": [
        "Prepare the sample instance in the format expected by the model signature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHuRrUjvuK0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_tf_features(instance):\n",
        " \n",
        "  new_instance = {}\n",
        "  for key, value in instance.items():\n",
        "    if key in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n",
        "      new_instance[key] = tf.constant(value, dtype=tf.string)\n",
        "    else:\n",
        "      new_instance[key] = tf.constant(value, dtype=tf.float32)\n",
        "  \n",
        "  return new_instance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKVRSluEWCRb",
        "colab_type": "text"
      },
      "source": [
        "Load the SavedModel for prediction, and then create a function that generates the prediction probabilities from the model to return the class label with the highest probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUaWFXqgu96i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_predictor = tf.saved_model.load(MODEL_DIR).signatures[SIGNATURE_NAME]\n",
        "\n",
        "def local_predict(instance):\n",
        "  features = create_tf_features(instance)\n",
        "  outputs = features_predictor(**features)\n",
        "  return outputs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J6SZ6jwWHJW",
        "colab_type": "text"
      },
      "source": [
        "Predict using the local SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2obiJWB20BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = local_predict(instances[0])\n",
        "predictions = list(\n",
        "    zip(outputs[LABEL_KEY].numpy().tolist(), \n",
        "        outputs[SCORE_KEY].numpy().tolist()))\n",
        "\n",
        "for prediction in predictions:\n",
        "  print(\"Predicted label: {} - Prediction confidence: {}\".format(\n",
        "        prediction[0], round(prediction[1], 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY-3txmZb0kf",
        "colab_type": "text"
      },
      "source": [
        "### 3.4  Upload the exported model to Cloud Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6X0wsuJb0rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil rm -r gs://{BUCKET}/models/{MODEL_NAME}\n",
        "!gsutil cp -r {MODEL_DIR} gs://{BUCKET}/models/{MODEL_NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvVcRazvL_95",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model deployment to AI Platform \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uncXaPUBdBpV",
        "colab_type": "text"
      },
      "source": [
        "### 4.1. Create model in AI Platform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO5a1fGLLrSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud ai-platform models create {MODEL_NAME} \\\n",
        "  --project {PROJECT_ID} \\\n",
        "  --regions {REGION}\n",
        "\n",
        "# List the models\n",
        "!gcloud ai-platform models list --project {PROJECT_ID}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmUPxnCZdJZ4",
        "colab_type": "text"
      },
      "source": [
        "### 4.2. Create a model version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW-zQi9bZzF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --model={MODEL_NAME} \\\n",
        "  --origin=gs://{BUCKET}/models/{MODEL_NAME} \\\n",
        "  --runtime-version=2.1 \\\n",
        "  --framework=TENSORFLOW \\\n",
        "  --python-version=3.7 \\\n",
        "  --project={PROJECT_ID}\n",
        "\n",
        "# List the model versions\n",
        "!gcloud ai-platform versions list --model={MODEL_NAME} --project={PROJECT_ID}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmFimRVrc4m8",
        "colab_type": "text"
      },
      "source": [
        "### 4.3. Test the deployed model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dGRzGf0Wcth",
        "colab_type": "text"
      },
      "source": [
        "Create a function to call the AI Platform Prediction model version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJJDQNMzc4xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import googleapiclient.discovery\n",
        "\n",
        "service = googleapiclient.discovery.build('ml', 'v1')\n",
        "name = 'projects/{}/models/{}/versions/{}'.format(PROJECT_ID, MODEL_NAME, VERSION_NAME)\n",
        "print(\"Service name: {}\".format(name))\n",
        "\n",
        "def caip_predict(instances):\n",
        "  \n",
        "  request_body={\n",
        "      'signature_name': SIGNATURE_NAME,\n",
        "      'instances': instances}\n",
        "\n",
        "  response = service.projects().predict(\n",
        "      name=name,\n",
        "      body=request_body\n",
        "\n",
        "  ).execute()\n",
        "\n",
        "  if 'error' in response:\n",
        "    raise RuntimeError(response['error'])\n",
        "\n",
        "  outputs = response['predictions']\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3WZZSqyWeGZ",
        "colab_type": "text"
      },
      "source": [
        "Predict using AI Platform Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbgnmaks4UPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = caip_predict(instances)\n",
        "for output in outputs:\n",
        "  print(\"Predicted label: {} - Prediction confidence: {}\".format(\n",
        "        output[LABEL_KEY], round(output[SCORE_KEY], 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m11-MCflLjFG",
        "colab_type": "text"
      },
      "source": [
        "## 5. BigQuery logging dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmWQwyAUdwIW",
        "colab_type": "text"
      },
      "source": [
        "### 5.1. Create the BigQuery dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne38zMEKL_Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "client = bigquery.Client(PROJECT_ID)\n",
        "dataset_names = [dataset.dataset_id for dataset in client.list_datasets(PROJECT_ID)]\n",
        "\n",
        "dataset = bigquery.Dataset(\"{}.{}\".format(PROJECT_ID, BQ_DATASET_NAME))\n",
        "dataset.location = \"US\"\n",
        "\n",
        "if BQ_DATASET_NAME not in dataset_names:\n",
        "  dataset = client.create_dataset(dataset)\n",
        "  print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n",
        "\n",
        "print(\"BigQuery dataset is ready.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieIgLE94PovQ",
        "colab_type": "text"
      },
      "source": [
        "### 5.2. Create the BigQuery table to store the logs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ima0Dg1UWkRO",
        "colab_type": "text"
      },
      "source": [
        "#### Table schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqxS6RQ0T9LG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "table_schema_json = [\n",
        "  {\n",
        "    \"name\": \"model\", \n",
        "    \"type\": \"STRING\", \n",
        "    \"mode\": \"REQUIRED\"\n",
        "   },\n",
        "   {\n",
        "     \"name\":\"model_version\", \n",
        "     \"type\": \"STRING\", \n",
        "     \"mode\":\"REQUIRED\"\n",
        "  },\n",
        "  {\n",
        "    \"name\":\"time\", \n",
        "    \"type\": \"TIMESTAMP\", \n",
        "    \"mode\": \"REQUIRED\"\n",
        "  },\n",
        "  {\n",
        "    \"name\":\"raw_data\", \n",
        "    \"type\": \"STRING\", \n",
        "    \"mode\": \"REQUIRED\"\n",
        "  },\n",
        "  {\n",
        "    \"name\":\"raw_prediction\", \n",
        "    \"type\": \"STRING\", \n",
        "    \"mode\": \"NULLABLE\"\n",
        "  },\n",
        "  {\n",
        "    \"name\":\"groundtruth\", \n",
        "    \"type\": \"STRING\", \n",
        "    \"mode\": \"NULLABLE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "json.dump(\n",
        "    table_schema_json, open('table_schema.json', 'w'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koE5tKouWngb",
        "colab_type": "text"
      },
      "source": [
        "#### Creating an ingestion-time partitioned table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXkoAGEiXRvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table = bigquery.Table(\n",
        "    \"{}.{}.{}\".format(PROJECT_ID, BQ_DATASET_NAME, BQ_TABLE_NAME))\n",
        "\n",
        "table_names = [table.table_id for table in client.list_tables(dataset)]\n",
        "\n",
        "if BQ_TABLE_NAME in table_names:\n",
        "  print(\"Deleting BQ table: {} ...\".format(BQ_TABLE_NAME))\n",
        "  client.delete_table(table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnE9GMjbeqXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TIME_PARTITION_EXPERIATION = int(60 * 60 * 24 * 7)\n",
        "\n",
        "!bq mk --table \\\n",
        "  --project_id={PROJECT_ID} \\\n",
        "  --time_partitioning_field=time \\\n",
        "  --time_partitioning_type=DAY \\\n",
        "  --time_partitioning_expiration={TIME_PARTITION_EXPERIATION} \\\n",
        "  {PROJECT_ID}:{BQ_DATASET_NAME}.{BQ_TABLE_NAME} \\\n",
        "  'table_schema.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPFM4mW-R3y8",
        "colab_type": "text"
      },
      "source": [
        "### 5.3. Configure the AI Platform model version to enable request-response logging to BigQuery\n",
        "\n",
        "In order to enable the request-response logging to an existing AI Platform Prediction model version, you need to call the `patch` API and populate the [requestLoggingConfig](https://cloud.google.com/ai-platform/prediction/docs/online-predict#requesting_logs_for_online_prediction_requests) field."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBkx4i9Rc51W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampling_percentage = 1.0\n",
        "bq_full_table_name = '{}.{}.{}'.format(PROJECT_ID, BQ_DATASET_NAME, BQ_TABLE_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EarF0cmcRZN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging_config = {\n",
        "    \"requestLoggingConfig\":{\n",
        "        \"samplingPercentage\": sampling_percentage,\n",
        "        \"bigqueryTableName\": bq_full_table_name\n",
        "        }\n",
        "    }\n",
        "\n",
        "service.projects().models().versions().patch(\n",
        "    name=name,\n",
        "    body=logging_config,\n",
        "    updateMask=\"requestLoggingConfig\"\n",
        "    ).execute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVpICSuq0Kp1",
        "colab_type": "text"
      },
      "source": [
        "### 5.4. Test request-response logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XVWG6y3XWIq",
        "colab_type": "text"
      },
      "source": [
        "Send sample prediction requests to the model version on AI Platform Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6YsfjkPtkx3o",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "for i in range(5):\n",
        "  caip_predict(instances)\n",
        "  print('.', end='')\n",
        "  time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgi_HyXIXcdg",
        "colab_type": "text"
      },
      "source": [
        "Query the logged request-response entries in BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdlrKX0d0mQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = '''\n",
        "  SELECT * FROM \n",
        "  `{}.{}` \n",
        "  WHERE model_version = '{}'\n",
        "  ORDER BY time desc\n",
        "  LIMIT {}\n",
        "'''.format(BQ_DATASET_NAME, BQ_TABLE_NAME, VERSION_NAME, 3)\n",
        "\n",
        "pd.io.gbq.read_gbq(\n",
        "    query, project_id=PROJECT_ID).T\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Aifkm5ErndR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}